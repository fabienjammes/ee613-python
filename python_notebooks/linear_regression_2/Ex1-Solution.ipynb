{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE613 - Linear Regression II - Exercise 1 (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "from numpy import dot\n",
    "\n",
    "#use 'inline' for plotting the figure inside the notebook, and 'qt' for pop-up plot\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=4,suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this exercise, we want to apply logistic regression to classify between two letters, $C_1$ and $C_2$, given the data $x$. The probability of belonging to the first class $C_1$ can be formulated as: \n",
    "$$P(C_1 | x) = \\frac{1}{1 + exp(-A^\\top x)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '../python_data/2Dletters/'\n",
    "\n",
    "#take the first letter data\n",
    "data = np.load(ROOT + 'U.npy')\n",
    "data = data.transpose([0,2,1])\n",
    "data = data[:,::5,:]\n",
    "num_data_1 = len(data)\n",
    "\n",
    "#take the second letter data\n",
    "data2 = np.load(ROOT + 'V.npy')\n",
    "data2 = data2.transpose([0,2,1])\n",
    "data2 = data2[:,::5,:]\n",
    "num_data_2 = len(data2)\n",
    "\n",
    "#combine the data\n",
    "data_full = np.concatenate((data,data2),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot random sample from the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f74b7cd4050>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(len(data_full))\n",
    "data_i = data_full[random_index]\n",
    "plt.plot(data_i[:,0], data_i[:,1],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the input and output, and separate into training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#the input is the letter trajectory data {x1,x2}, and the output is a binary variable {0,1}\n",
    "N = data_full.shape[0]\n",
    "data_full = data_full.reshape(N,-1) #concatenating x1 and x2 variables into a vector\n",
    "X = np.concatenate([np.ones((N,1)), data_full.reshape(N,-1)], axis=1)\n",
    "Y = np.concatenate([np.ones(num_data_1),np.zeros(num_data_2)])[:,None] #the output value for the first letter is 1, and 0 for the second letter\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "Using $X_{train}$ and $Y_{train}$, obtain the logistic regression parameters $A$ by IRLS, and use that to predict the correct letters on $X_{test}$. Compare the prediction to the true value, $Y_{test}$, at different iterations of IRLS. You can look at demo_logistic_regression.ipynb for an example. (Note: chose an array of zeros as the initial value of $A$).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "When constructing the input $X$ above, why do we need to add np.ones((N,1))?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X,Y, X_test=None, Y_test = None, nb_iter = 5, lamda = 0.1):\n",
    "    n_in = X.shape[1]\n",
    "    a = np.zeros((n_in,1))\n",
    "    res = []\n",
    "    L_prev = np.inf\n",
    "    for i in range(nb_iter):\n",
    "        mu = 1./(1 + np.exp(-dot(X,a))) #prediction\n",
    "        W = np.diag((mu * (1-mu)).flatten())\n",
    "        a = dot(inv(dot(X.T,dot(W,X))+1e-7*np.eye(n_in)),dot(X.T, dot(W,dot(X,a))+(Y-mu)))\n",
    "        \n",
    "        if Y_test is not None:\n",
    "            Y_pred = 1./(1 + np.exp(-dot(X_test,a)))\n",
    "            res += [np.linalg.norm(Y_pred-Y_test)]\n",
    "\n",
    "    return a, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error at iteration 0 is 0.568575261501\n",
      "The error at iteration 1 is 0.504887596634\n",
      "The error at iteration 2 is 0.491308625902\n",
      "The error at iteration 3 is 0.486266617067\n",
      "The error at iteration 4 is 0.482947969825\n",
      "The error at iteration 5 is 0.479932989013\n",
      "The error at iteration 6 is 0.476736311111\n",
      "The error at iteration 7 is 0.472732406355\n",
      "The error at iteration 8 is 0.466258232498\n",
      "The error at iteration 9 is 0.452519773054\n"
     ]
    }
   ],
   "source": [
    "A,res = logistic_regression(X_train, Y_train, X_test, Y_test, nb_iter = 10)\n",
    "\n",
    "for i,r in enumerate(res):\n",
    "    print('The error at iteration {} is {}'.format(i,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the equation: \n",
    "$$P(C_1 | x) = \\frac{1}{1 + exp(-A^\\top x)} $$\n",
    "\n",
    "we want to have a bias term, so the term inside the exponential should actually be $$A^\\top x + b.$$ A nice way of doing this is to rewrite it in the following format:\n",
    "$$A^\\top x + b  =  [b \\quad A^\\top] \\begin{bmatrix} 1\\\\ x\\\\ \\end{bmatrix} = \\hat{A}^\\top \\hat{x}$$\n",
    "\n",
    "where $\\hat{A}$ and $\\hat{x}$ are the new defined variables. So by adding 1 to our $x$, we can get the bias term inside $\\hat{A}$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
